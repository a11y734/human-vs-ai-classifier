## Why
Build a simple, fast Chinese + English text classifier that estimates whether input text is written by a human or generated by AI, using the HC3-Chinese CSV dataset (from chatgpt-comparison-detection) plus the optional English reference dataset under `refs/human-vs-ai-text-classifier/`. Deliver an immediate, user-friendly Streamlit UI that outputs AI% / Human% plus confidence, with basic visualizations and optional explanations.

## What Changes
- Introduce a baseline Chinese + English classifier pipeline (sklearn TF‑IDF + Logistic Regression/SVM) trained on HC3-Chinese CSVs and, optionally, merged with an English reference CSV when enabled via a flag.
- Persist artifacts (vectorizer + model) for inference, plus metrics and charts (confusion matrix, ROC/PR, dataset stats).
- Provide a Streamlit UI for single‑text inference with AI% / Human% output, confidence, and optional feature‑importance explanation.
- Keep code modular (training script, inference module, Streamlit app) with clear README run commands.
- Treat Traditional and Simplified Chinese as the same language category; prefer preprocessing unification to Simplified when available (fallback to character n‑gram features if unavailable).
- Add a bilingual training flag `--include-english` to optionally merge English reference data from `refs/human-vs-ai-text-classifier/data/*.csv` (schema: `text`,`label`) with Chinese data, applying language/class balancing to avoid skew.

## Impact
- Enables local, low‑latency classification and quick demo UX.
- Establishes a clear artifact contract for UI/runtime to load.
- Creates a foundation for future model upgrades without breaking the UI.
- Enables Chinese‑only or bilingual Chinese+English models from the same pipeline via a simple flag, while avoiding fragmentation from script variance.

## Out of Scope (Now)
- Training large transformer models.
- Online learning or continuous dataset ingestion.
- Multi‑language support outside Chinese and English.

## Risks and Mitigations
- Small/imbalanced dataset — use stratified split and class weights; report metrics.
- Tokenization complexity for Chinese — start with char‑level n‑grams TF‑IDF to avoid external deps.
- Model drift — provide simple retrain script path in tasks.
- Language skew when mixing datasets — apply language/class balancing (sampling or class_weight) and validate per‑language metrics; document the flag clearly.
- Script variance (Traditional vs Simplified) — prefer unification to Simplified during preprocessing; otherwise rely on character n‑grams to mitigate.
